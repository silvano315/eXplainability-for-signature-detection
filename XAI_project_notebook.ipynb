{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cbc264",
   "metadata": {},
   "source": [
    "# XAI Project for signature classification using CEDAR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821236a",
   "metadata": {},
   "source": [
    "## Configurations Colab & Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/silvano315/eXplainability-for-signature-detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e246a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"eXplainability-for-signature-detection\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move your Kaggle API to /root/.config/kaggle and /root/.kaggle/kaggle.json\n",
    "\n",
    "os.makedirs('/root/.kaggle', exist_ok = True)\n",
    "\n",
    "!cp /content/drive/MyDrive/Kaggle_api/kaggle.json /root/.config/kaggle.json\n",
    "!cp /content/drive/MyDrive/Kaggle_api/kaggle.json /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49734ac8",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from src.utils.kaggle_downloader import setup_dataset\n",
    "from src.utils.logger_setup import get_logger\n",
    "from src.utils.dataset_analyzer import create_dataset_metadata, validate_dataset_consistency, \\\n",
    "                                        save_metadata, load_metadata\n",
    "from src.utils.eda import print_dataset_statistics, plot_dataset_distribution, \\\n",
    "                            show_sample_images, analyze_image_properties, generate_eda_report\n",
    "from src.data.cedar_dataset import CEDARDataset, create_dataloaders, create_balanced_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a74a5",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "\n",
    "with open('config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acabf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "\n",
    "DATA_PATH = Path(config['paths']['data']['raw_path'])\n",
    "MODELS_PATH = Path(config['paths']['data']['models_path'])\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d42f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "BATCH_SIZE = config['training']['batch_size']\n",
    "NUM_EPOCHS = config['training']['num_epochs']\n",
    "LEARNING_RATE = config['training']['learning_rate']\n",
    "NUM_CLASSES = config['dataset']['num_classes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1ede8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298caa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Malimg dataset from Kaggle\n",
    "\n",
    "dataset_path = setup_dataset()\n",
    "print(f\"Dataset found at: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate metadata for the dataset\n",
    "\n",
    "signatures_path = Path(\"data/raw/cedardataset/signatures\")\n",
    "metadata = create_dataset_metadata(signatures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or load metadata with FLAG\n",
    "\n",
    "SAVE_METADATA = False\n",
    "dataset_metadata_path = Path(\"metadata/metadata.json\")\n",
    "\n",
    "if SAVE_METADATA:\n",
    "    save_metadata(metadata, dataset_metadata_path)\n",
    "else:\n",
    "    metadata = load_metadata(dataset_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate dataset consistency (statistics, class distribution, etc.)\n",
    "\n",
    "validate_metadata = validate_dataset_consistency(metadata)\n",
    "for key, value in validate_metadata.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for subkey, subvalue in value.items():\n",
    "            print(f\"  {subkey}: {subvalue}\")\n",
    "    else:\n",
    "      print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65385e4",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ad6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a complete EDA report\n",
    "\n",
    "signatures_path = Path(\"data/raw/cedardataset/signatures\")\n",
    "output_dir = Path(\"reports/eda\")\n",
    "\n",
    "generate_eda_report(signatures_path, metadata, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebe1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I you want to run the EDA report step by step\n",
    "\n",
    "print_dataset_statistics(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c92b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I you want to run the EDA report step by step\n",
    "\n",
    "plot_dataset_distribution(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cdd330",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't run it before\n",
    "\n",
    "dataset_metadata_path = Path(\"metadata/metadata.json\")\n",
    "\n",
    "metadata = load_metadata(dataset_metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84659a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata with balanced splits\n",
    "\n",
    "metadata_with_splits = create_balanced_splits(metadata)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"You can see the split key updated\")\n",
    "for i, (key, value) in enumerate(metadata_with_splits.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    if i == 5:\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1438a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for training, validation, and test sets\n",
    "\n",
    "data_path = Path(\"data/raw/cedardataset/signatures\")\n",
    "\n",
    "dataloaders = create_dataloaders(data_path, metadata_with_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9552c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the dataloaders for each split\n",
    "\n",
    "for split, loader in dataloaders.items():\n",
    "    print(f\"{split} DataLoader:\")\n",
    "    for i, (images, labels) in enumerate(loader):\n",
    "        print(f\"  Batch {i+1}: {len(images)} images\")\n",
    "        print(f\"  Labels: {labels}\")\n",
    "        print(f\"  Images shape: {images.shape}\")\n",
    "        if i == 2:\n",
    "            break\n",
    "    print(\"\\n\")\n",
    "    print(f\"Class counts: {loader.dataset.get_class_counts()}\")\n",
    "    print(f\"Subject info: {loader.dataset.get_subject_info()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
